_target_: src.models.modelmodule.DINRTraining

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 1e-3
  weight_decay: 1e-5

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

criterion:
  _target_: torch.nn.MSELoss

net:
  _target_: src.models.components.Dynamical_FINERNet.DynamicalFINER
  input_dim: 2
  hidden_dim: 256
  output_dim: 3
  num_layers: 2
  omega_0: 15.0
  omega_0_hidden: 15.0
  dropout_rate: 0.0
  block_type: "residual"
  num_steps: 12
  total_time: 1.0
  ot_lambda: 0.001
  first_bias_scale: null
  scale_req_grad: false
  final_activation: null

compile: false

ntk_analysis: false
ntk_frequency: 2
ntk_top_k: 10
ntk_normalize: "trace"

checkpoint_epochs: []

ablation_ot_loss: false
ablation_noise: false
noise_type: "gaussian"
noise_level: 0.01
